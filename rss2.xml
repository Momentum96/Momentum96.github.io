<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>눈높이코딩</title>
    <link>https://github.aivillain.com/</link>
    
    <atom:link href="https://github.aivillain.com/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>Momentum&#39;s blog</description>
    <pubDate>Wed, 10 Feb 2021 14:23:46 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>Kaggle Titanic Solve</title>
      <link>https://github.aivillain.com/2021/02/10/kr/Titanic_solve_using_scikit_learn/</link>
      <guid>https://github.aivillain.com/2021/02/10/kr/Titanic_solve_using_scikit_learn/</guid>
      <pubDate>Tue, 09 Feb 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;This article is also</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>This article is also available in<a href="">English</a>.</div></article><p><a href="https://github.com/Momentum96/Study/blob/main/ML/Titanic/Titanic%20solve%20using%20scikit-learn.ipynb">jupyter notebook 코드 링크</a></p><p>캐글(kaggle) 타이타닉을 활용한 머신러닝 실습</p>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Machine-Learning/">Machine Learning</category>
      
      
      <category domain="https://github.aivillain.com/tags/%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D/">머신 러닝</category>
      
      <category domain="https://github.aivillain.com/tags/%EC%82%AC%EC%9D%B4%ED%82%B7-%EB%9F%B0/">사이킷 런</category>
      
      <category domain="https://github.aivillain.com/tags/%EC%BA%90%EA%B8%80/">캐글</category>
      
      
      <comments>https://github.aivillain.com/2021/02/10/kr/Titanic_solve_using_scikit_learn/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Kaggle Titanic Solve</title>
      <link>https://github.aivillain.com/2021/02/10/en/Titanic_solve_using_scikit_learn/</link>
      <guid>https://github.aivillain.com/2021/02/10/en/Titanic_solve_using_scikit_learn/</guid>
      <pubDate>Tue, 09 Feb 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;이 글은
&lt;a href=&quot;/2021/</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>이 글은<a href="/2021/02/10/kr/Titanic_solve_using_scikit_learn/">한국어</a>로도 볼 수 있습니다.</div></article><article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-info-circle mr-2"></i>My English is not good. So if there is a grammatical error, please leave a comment.</div></article><p><a href="https://github.com/Momentum96/Study/blob/main/ML/Titanic/Titanic%20solve%20using%20scikit-learn.ipynb">jupyter notebook code link</a></p><p>Machine learning practice using the Kaggle Titanic dataset</p>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Machine-Learning/">Machine Learning</category>
      
      
      <category domain="https://github.aivillain.com/tags/Machine-Learning/">Machine Learning</category>
      
      <category domain="https://github.aivillain.com/tags/scikit-learn/">scikit-learn</category>
      
      <category domain="https://github.aivillain.com/tags/Kaggle/">Kaggle</category>
      
      
      <comments>https://github.aivillain.com/2021/02/10/en/Titanic_solve_using_scikit_learn/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Scikit-Learn-3 (Model Selection)</title>
      <link>https://github.aivillain.com/2021/02/02/en/Scikit-Learn-3/</link>
      <guid>https://github.aivillain.com/2021/02/02/en/Scikit-Learn-3/</guid>
      <pubDate>Mon, 01 Feb 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;이 글은
&lt;a href=&quot;/2021/</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>이 글은<a href="/2021/02/02/kr/Scikit-Learn-3/">한국어</a>로도 볼 수 있습니다.</div></article><article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-info-circle mr-2"></i>My English is not good. So if there is a grammatical error, please leave a comment.</div></article><h3 id="Model-Selection-Module"><a href="#Model-Selection-Module" class="headerlink" title="Model Selection Module"></a>Model Selection Module</h3><hr><p>Separate learning data, test data, or split and evaluate cross-validation, tuning the estimator’s hyperparameters</p><h3 id="train-test-split"><a href="#train-test-split" class="headerlink" title="train_test_split()"></a>train_test_split()</h3><hr><ul><li>test_size : Size of test data</li><li>shuffle : Settings for pre-mixing data. default is True</li><li>random_state : Random number of values to generate the same learning, dataset for each call</li></ul><p>Return values are in tuple shape</p><h3 id="Cross-Validation"><a href="#Cross-Validation" class="headerlink" title="Cross Validation"></a>Cross Validation</h3><hr><p>Vulnerable to overfitting just by dividing learning, test data<br>Overfitting: Model over-optimizes to learning data only, resulting in excessive prediction performance<br>Perform evaluations on training and validation data consisting of multiple separate sets</p><p>After a cross-validation-based primary evaluation, it is common to finally apply to test data for evaluation.</p><h3 id="K-fold-Cross-Validation"><a href="#K-fold-Cross-Validation" class="headerlink" title="K-fold Cross Validation"></a>K-fold Cross Validation</h3><hr><p>Create a set of K datafolds to repeatedly evaluate verification on each fold set as many times as K times.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">features = iris.data</span><br><span class="line">label = iris.target</span><br><span class="line">dt_clf = DecisionTreeClassifier(random_state=<span class="number">156</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create 5 Folds</span></span><br><span class="line">kfold = KFold(n_splits=<span class="number">5</span>)</span><br><span class="line">cv_accuracy = []</span><br><span class="line">print(<span class="string">&quot;붓꽃 데이터 크기 :&quot;</span>, features.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">n_iter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># split() of the KFold object returns the low index of the test for per-fold learning and validation as array</span></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> kfold.split(features):</span><br><span class="line">    X_train, X_test = features[train_index], features[test_index]</span><br><span class="line">    y_train, y_test = label[train_index], label[test_index]</span><br><span class="line"></span><br><span class="line">    dt_clf.fit(X_train, y_train)</span><br><span class="line">    pred = dt_clf.predict(X_test)</span><br><span class="line">    n_iter += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    accuracy = np.<span class="built_in">round</span>(accuracy_score(y_test, pred), <span class="number">4</span>)</span><br><span class="line">    train_size = X_train.shape[<span class="number">0</span>]</span><br><span class="line">    test_size = X_test.shape[<span class="number">0</span>]</span><br><span class="line">    print(<span class="string">&#x27;\n#&#123;0&#125; Cross-validation accuracy :&#123;1&#125;, train data size: &#123;2&#125;, validation data size: &#123;3&#125;&#x27;</span>.<span class="built_in">format</span>(n_iter, accuracy, train_size, test_size))</span><br><span class="line">    print(<span class="string">&#x27;#&#123;0&#125; index of validation set: &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(n_iter, test_index))</span><br><span class="line">    cv_accuracy.append(accuracy)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;\n## Average accuracy of validation:&#x27;</span>, np.mean(cv_accuracy))</span><br></pre></td></tr></table></figure><h3 id="Stratified-K-fold"><a href="#Stratified-K-fold" class="headerlink" title="Stratified K fold"></a>Stratified K fold</h3><hr><p>K-fold scheme for label datasets with unbalanced distributions.<br>The distribution of a particular label is skewed due to its unusually high or low value.</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">dt_clf = DecisionTreeClassifier(random_state=<span class="number">156</span>)</span><br><span class="line"></span><br><span class="line">features = iris.data</span><br><span class="line">label = iris.target</span><br><span class="line">skfold = StratifiedKFold(n_splits=<span class="number">3</span>)</span><br><span class="line">n_iter=<span class="number">0</span></span><br><span class="line">cv_accuracy = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> skfold.split(features, label):</span><br><span class="line">    X_train, X_test = features[train_index], features[test_index]</span><br><span class="line">    y_train, y_test = label[train_index], label[test_index]</span><br><span class="line"></span><br><span class="line">    dt_clf.fit(X_train, y_train)</span><br><span class="line">    pred = dt_clf.predict(X_test)</span><br><span class="line"></span><br><span class="line">    n_iter += <span class="number">1</span></span><br><span class="line">    accuracy = np.<span class="built_in">round</span>(accuracy_score(y_test, pred), <span class="number">4</span>)</span><br><span class="line">    train_size = X_train.shape[<span class="number">0</span>]</span><br><span class="line">    test_size = X_test.shape[<span class="number">0</span>]</span><br><span class="line">    print(<span class="string">&#x27;\n#&#123;0&#125; Cross-validation accuracy :&#123;1&#125;, train data size: &#123;2&#125;, validation data size: &#123;3&#125;&#x27;</span>.<span class="built_in">format</span>(n_iter, accuracy, train_size, test_size))</span><br><span class="line">    print(<span class="string">&#x27;#&#123;0&#125; index of validation set: &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(n_iter, test_index))</span><br><span class="line">    cv_accuracy.append(accuracy)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;\n## Accuracy by cross validation:&#x27;</span>, np.<span class="built_in">round</span>(cv_accuracy, <span class="number">4</span>))</span><br><span class="line">print(<span class="string">&#x27;## Average accuracy of validation:&#x27;</span>, np.mean(cv_accuracy))</span><br></pre></td></tr></table></figure><h3 id="cross-val-score"><a href="#cross-val-score" class="headerlink" title="cross_val_score()"></a>cross_val_score()</h3><hr><p>API that make cross-validation more convenient</p><p>KFold’s Data Learning, Predictive Code</p><ol><li>Specify Fold Set</li><li>for loop learning iterations, extracting test data indexes</li><li>Learning and making predictions repeatedly</li></ol><p>cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pred_dispatch=’2*n_jobs’)</p><ul><li>estimator : Classifier or Regression</li><li>X : Feature Dataset</li><li>y : Label Dataset</li><li>scoring : Predictive Performance Evaluation Indicators</li><li>cv : Number of cross-validation folds</li></ul><p>Returns the performance indicator measurement specified by the scoring parameter in array form</p><p>cross_validate() can return multiple evaluation metrics</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score, cross_validate</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">iris_data = load_iris()</span><br><span class="line">dt_clf = DecisionTreeClassifier(random_state=<span class="number">156</span>)</span><br><span class="line"></span><br><span class="line">data = iris_data.data</span><br><span class="line">label = iris_data.target</span><br><span class="line"></span><br><span class="line">scores = cross_val_score(dt_clf, data, label, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">3</span>)</span><br><span class="line">print(<span class="string">&quot;Cross-validation accuracy:&quot;</span>, np.<span class="built_in">round</span>(scores, <span class="number">4</span>))</span><br><span class="line">print(<span class="string">&quot;Average accuracy of validation:&quot;</span>, np.<span class="built_in">round</span>(np.mean(scores), <span class="number">4</span>))</span><br></pre></td></tr></table></figure><h3 id="GridSearchCV"><a href="#GridSearchCV" class="headerlink" title="GridSearchCV"></a>GridSearchCV</h3><hr><p>cross-validation, tuning the optimal hyperparameters<br>Hyperparameters: the main components of machine learning algorithms<br>You can adjust this value to improve the predictive performance of the algorithm.</p><p>Allows you to find the optimal value of the hyperparameters based on cross-validation</p><p>Parameters</p><ul><li>estimator</li><li>param_grid : Dictionary that key + list value. parameter name, parameter value specification for estimator tuning</li><li>scoring : Predictive Performance Evaluation Indicators</li><li>cv : Number of cross-validation folds</li><li>refit : Find the most optimal hyperparameter and re-educate the estimator object to that hyperparameter (default = True)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV, train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=<span class="number">0.2</span>, random_state=<span class="number">121</span>)</span><br><span class="line"></span><br><span class="line">dtree = DecisionTreeClassifier(random_state=<span class="number">121</span>)</span><br><span class="line"></span><br><span class="line">parameters = &#123;<span class="string">&#x27;max_depth&#x27;</span>:[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">&#x27;min_samples_split&#x27;</span>:[<span class="number">2</span>, <span class="number">3</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=<span class="number">3</span>, refit=<span class="literal">True</span>)</span><br><span class="line">grid_dtree.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">scores_df = pd.DataFrame(grid_dtree.cv_results_)</span><br><span class="line">print(scores_df[[<span class="string">&#x27;params&#x27;</span>, <span class="string">&#x27;mean_test_score&#x27;</span>, <span class="string">&#x27;rank_test_score&#x27;</span>, <span class="string">&#x27;split0_test_score&#x27;</span>, <span class="string">&#x27;split1_test_score&#x27;</span>, <span class="string">&#x27;split2_test_score&#x27;</span>]])</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;GridSearchCV Optimal Parameters:&#x27;</span>, grid_dtree.best_params_)</span><br><span class="line">print(<span class="string">&#x27;GridSearchCV Highest Accuracy:&#123;0:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(grid_dtree.best_score_))</span><br><span class="line"></span><br><span class="line">estimator = grid_dtree.best_estimator_</span><br><span class="line"></span><br><span class="line">pred = estimator.predict(X_test)</span><br><span class="line">print(<span class="string">&#x27;Test Dataset Accuracy: &#123;0:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(accuracy_score(y_test, pred)))</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Machine-Learning/">Machine Learning</category>
      
      
      <category domain="https://github.aivillain.com/tags/Machine-Learning/">Machine Learning</category>
      
      <category domain="https://github.aivillain.com/tags/Scikit-learn/">Scikit learn</category>
      
      
      <comments>https://github.aivillain.com/2021/02/02/en/Scikit-Learn-3/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Scikit-Learn-4 (Preprocessing))</title>
      <link>https://github.aivillain.com/2021/02/02/en/Scikit-Learn-4/</link>
      <guid>https://github.aivillain.com/2021/02/02/en/Scikit-Learn-4/</guid>
      <pubDate>Mon, 01 Feb 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;이 글은
&lt;a href=&quot;/2021/</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>이 글은<a href="/2021/02/02/kr/Scikit-Learn-4/">한국어</a>로도 볼 수 있습니다.</div></article><article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-info-circle mr-2"></i>My English is not good. So if there is a grammatical error, please leave a comment.</div></article><h3 id="Data-Preprocessing"><a href="#Data-Preprocessing" class="headerlink" title="Data Preprocessing"></a>Data Preprocessing</h3><hr><p>Basics to preprocess data before applying ML algorithms</p><ul><li>Nan, Null<br>Need to convert to another fixed value<br>If it’s not long, it can be replaced by the average value of the feature.<br>It is better to drop features if most null values are Null</li><li>String<br>Do not allow as input value<br>Must be converted to numeric via encoding<br>Categorized by Category, Text Feature<br>Text-type features are vectorized by techniques such as feature vectorization, and drop if necessary.</li></ul><h3 id="Data-Encoding"><a href="#Data-Encoding" class="headerlink" title="Data Encoding"></a>Data Encoding</h3><hr><ul><li><p>Label Encoding<br>Converting category features to numeric values</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line">items=[<span class="string">&#x27;TV&#x27;</span>, <span class="string">&#x27;냉장고&#x27;</span>, <span class="string">&#x27;전자레인지&#x27;</span>, <span class="string">&#x27;컴퓨터&#x27;</span>, <span class="string">&#x27;선풍기&#x27;</span>, <span class="string">&#x27;선풍기&#x27;</span>, <span class="string">&#x27;믹서&#x27;</span>, <span class="string">&#x27;믹서&#x27;</span>]</span><br><span class="line"></span><br><span class="line">encoder = LabelEncoder()</span><br><span class="line">encoder.fit(items)</span><br><span class="line">labels = encoder.transform(items)</span><br><span class="line">print(<span class="string">&#x27;Encoding conversion value:&#x27;</span>, labels)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Encoding Class:&#x27;</span>, encoder.classes_)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Decode Source Value:&#x27;</span>, encoder.inverse_transform([<span class="number">4</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>]))</span><br></pre></td></tr></table></figure></li><li><p>One-Hot Encoding<br>Add new features according to the type of feature value<br>Show 1 only in columns corresponding to unique values, 0 in remaining columns</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder, LabelEncoder</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">items=[<span class="string">&#x27;TV&#x27;</span>, <span class="string">&#x27;냉장고&#x27;</span>, <span class="string">&#x27;전자레인지&#x27;</span>, <span class="string">&#x27;컴퓨터&#x27;</span>, <span class="string">&#x27;선풍기&#x27;</span>, <span class="string">&#x27;선풍기&#x27;</span>, <span class="string">&#x27;믹서&#x27;</span>, <span class="string">&#x27;믹서&#x27;</span>]</span><br><span class="line"></span><br><span class="line">encoder = LabelEncoder()</span><br><span class="line">encoder.fit(items)</span><br><span class="line">labels = encoder.transform(items)</span><br><span class="line"></span><br><span class="line">labels = labels.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">print(labels)</span><br><span class="line"></span><br><span class="line">oh_encoder = OneHotEncoder()</span><br><span class="line">oh_encoder.fit(labels)</span><br><span class="line">oh_labels = oh_encoder.transform(labels)</span><br><span class="line">print(<span class="string">&#x27;One-Hot Encoded Data&#x27;</span>)</span><br><span class="line">print(oh_labels.toarray())</span><br><span class="line">print(<span class="string">&quot;One-Hot Encoded Data Dimensions&quot;</span>)</span><br><span class="line">print(oh_labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pandas OneHotEncoding API</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;item&#x27;</span>:items&#125;)</span><br><span class="line">print(pd.get_dummies(df))</span><br></pre></td></tr></table></figure><h3 id="Feature-scaling-and-normalization"><a href="#Feature-scaling-and-normalization" class="headerlink" title="Feature scaling and normalization"></a>Feature scaling and normalization</h3></li></ul><hr><p>To set a constant range of values for different variables<br>Standardization, Normalization</p><ul><li><p>Standardization<br>Convert to a value with a Gaussian normal distribution with mean 0, variance 1</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">iris_data = iris.data</span><br><span class="line">iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;Average of the features&#x27;</span>)</span><br><span class="line">print(iris_df.mean())</span><br><span class="line">print(<span class="string">&#x27;\nVariance of the features&#x27;</span>)</span><br><span class="line">print(iris_df.var())</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler <span class="comment"># 평균 0, 분산 1에 가깝게</span></span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">scaler.fit(iris_df)</span><br><span class="line">iris_scaled = scaler.transform(iris_df)</span><br><span class="line"></span><br><span class="line">iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)</span><br><span class="line">print(<span class="string">&#x27;Average of the features&#x27;</span>)</span><br><span class="line">print(iris_df_scaled.mean())</span><br><span class="line">print(<span class="string">&#x27;\nVariance of the features&#x27;</span>)</span><br><span class="line">print(iris_df_scaled.var())</span><br></pre></td></tr></table></figure></li><li><p>Normalization<br>Convert sizes to unify different feature sizes<br>ex) MinMaxScaler</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">iris_data = iris.data</span><br><span class="line">iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line">scaler.fit(iris_df)</span><br><span class="line">iris_scaled = scaler.transform(iris_df)</span><br><span class="line"></span><br><span class="line">iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)</span><br><span class="line">print(<span class="string">&#x27;Minimum Value of the features&#x27;</span>)</span><br><span class="line">print(iris_df_scaled.<span class="built_in">min</span>())</span><br><span class="line">print(<span class="string">&#x27;\nMaximum Value of the features&#x27;</span>)</span><br><span class="line">print(iris_df_scaled.<span class="built_in">max</span>())</span><br></pre></td></tr></table></figure></li></ul>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Machine-Learning/">Machine Learning</category>
      
      
      <category domain="https://github.aivillain.com/tags/Machine-Learning/">Machine Learning</category>
      
      <category domain="https://github.aivillain.com/tags/Scikit-learn/">Scikit learn</category>
      
      
      <comments>https://github.aivillain.com/2021/02/02/en/Scikit-Learn-4/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Scikit-Learn-3 (Model Selection)</title>
      <link>https://github.aivillain.com/2021/02/02/kr/Scikit-Learn-3/</link>
      <guid>https://github.aivillain.com/2021/02/02/kr/Scikit-Learn-3/</guid>
      <pubDate>Mon, 01 Feb 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;This article is also</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>This article is also available in<a href="/2021/02/02/en/Scikit-Learn-3/">English</a>.</div></article><h3 id="Model-Selection-모듈"><a href="#Model-Selection-모듈" class="headerlink" title="Model Selection 모듈"></a>Model Selection 모듈</h3><hr><p>학습 데이터, 테스트 데이터를 분리하거나 교차 검증 분할 및 평가, Estimator의 하이퍼 파라미터 튜닝</p><h3 id="train-test-split"><a href="#train-test-split" class="headerlink" title="train_test_split()"></a>train_test_split()</h3><hr><ul><li>test_size : 테스트 데이터의 크기</li><li>shuffle : 데이터를 미리 섞을지. default는 True</li><li>random_state : 호출 시 마다 동일한 학습, 데이터세트를 생성하기 위한 난수값</li></ul><p>반환값은 튜플 형태</p><h3 id="교차-검증"><a href="#교차-검증" class="headerlink" title="교차 검증"></a>교차 검증</h3><hr><p>학습, 테스트 데이터를 나누는 것만으로는 과적합(Overfitting)에 취약<br>과적합 : 모델이 학습 데이터에만 과도하게 최적화, 실제 예측 성능이 과도하게 떨어짐<br>별도의 여러 세트로 구성된 학습 데이터와 검증 데이터에서 평가 수행</p><p>교차 검증 기반 1차 평가 이후 최종적으로 테스트 데이터에 적용하여 평가하는것이 일반적</p><h3 id="K-fold-교차-검증"><a href="#K-fold-교차-검증" class="headerlink" title="K-fold 교차 검증"></a>K-fold 교차 검증</h3><hr><p>K개의 데이터 폴드 세트를 만들어 K번만큼 각 폴드 세트에 검증 평가를 반복적으로 수행</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> KFold</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">features = iris.data</span><br><span class="line">label = iris.target</span><br><span class="line">dt_clf = DecisionTreeClassifier(random_state=<span class="number">156</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5개의 폴드 생성</span></span><br><span class="line">kfold = KFold(n_splits=<span class="number">5</span>)</span><br><span class="line">cv_accuracy = []</span><br><span class="line">print(<span class="string">&quot;붓꽃 데이터 크기 :&quot;</span>, features.shape[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">n_iter = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># KFold 객체의 split()은 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환</span></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> kfold.split(features):</span><br><span class="line">    X_train, X_test = features[train_index], features[test_index]</span><br><span class="line">    y_train, y_test = label[train_index], label[test_index]</span><br><span class="line"></span><br><span class="line">    dt_clf.fit(X_train, y_train)</span><br><span class="line">    pred = dt_clf.predict(X_test)</span><br><span class="line">    n_iter += <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    accuracy = np.<span class="built_in">round</span>(accuracy_score(y_test, pred), <span class="number">4</span>)</span><br><span class="line">    train_size = X_train.shape[<span class="number">0</span>]</span><br><span class="line">    test_size = X_test.shape[<span class="number">0</span>]</span><br><span class="line">    print(<span class="string">&#x27;\n#&#123;0&#125; 교차 검증 정확도 :&#123;1&#125;, 학습 데이터 크기: &#123;2&#125;, 검증 데이터 크기: &#123;3&#125;&#x27;</span>.<span class="built_in">format</span>(n_iter, accuracy, train_size, test_size))</span><br><span class="line">    print(<span class="string">&#x27;#&#123;0&#125; 검증 세트 인덱스: &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(n_iter, test_index))</span><br><span class="line">    cv_accuracy.append(accuracy)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;\n## 평균 검증 정확도:&#x27;</span>, np.mean(cv_accuracy))</span><br></pre></td></tr></table></figure><h3 id="Stratified-K-fold"><a href="#Stratified-K-fold" class="headerlink" title="Stratified K fold"></a>Stratified K fold</h3><hr><p>불균형한 분포를 갖는 레이블 데이터 집합을 위한 K 폴드 방식.<br>특정 레이블 값이 특이하게 많거나 적어서 값의 분포가 치우친 것</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">dt_clf = DecisionTreeClassifier(random_state=<span class="number">156</span>)</span><br><span class="line"></span><br><span class="line">features = iris.data</span><br><span class="line">label = iris.target</span><br><span class="line">skfold = StratifiedKFold(n_splits=<span class="number">3</span>)</span><br><span class="line">n_iter=<span class="number">0</span></span><br><span class="line">cv_accuracy = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> train_index, test_index <span class="keyword">in</span> skfold.split(features, label):</span><br><span class="line">    X_train, X_test = features[train_index], features[test_index]</span><br><span class="line">    y_train, y_test = label[train_index], label[test_index]</span><br><span class="line"></span><br><span class="line">    dt_clf.fit(X_train, y_train)</span><br><span class="line">    pred = dt_clf.predict(X_test)</span><br><span class="line"></span><br><span class="line">    n_iter += <span class="number">1</span></span><br><span class="line">    accuracy = np.<span class="built_in">round</span>(accuracy_score(y_test, pred), <span class="number">4</span>)</span><br><span class="line">    train_size = X_train.shape[<span class="number">0</span>]</span><br><span class="line">    test_size = X_test.shape[<span class="number">0</span>]</span><br><span class="line">    print(<span class="string">&#x27;\n#&#123;0&#125; 교차 검증 정확도 :&#123;1&#125;, 학습 데이터 크기: &#123;2&#125;, 검증 데이터 크기: &#123;3&#125;&#x27;</span>.<span class="built_in">format</span>(n_iter, accuracy, train_size, test_size))</span><br><span class="line">    print(<span class="string">&#x27;#&#123;0&#125; 검증 세트 인덱스: &#123;1&#125;&#x27;</span>.<span class="built_in">format</span>(n_iter, test_index))</span><br><span class="line">    cv_accuracy.append(accuracy)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;\n## 교차 검증별 정확도:&#x27;</span>, np.<span class="built_in">round</span>(cv_accuracy, <span class="number">4</span>))</span><br><span class="line">print(<span class="string">&#x27;## 평균 검증 정확도:&#x27;</span>, np.mean(cv_accuracy))</span><br></pre></td></tr></table></figure><h3 id="cross-val-score"><a href="#cross-val-score" class="headerlink" title="cross_val_score()"></a>cross_val_score()</h3><hr><p>교차 검증을 좀 더 편리하게 수행할 수 있게 해주는 API</p><p>KFold의 데이터 학습, 예측 코드</p><ol><li>폴드 세트 지정</li><li>for 루프에서 반복 학습, 테스트 데이터 인덱스 추출</li><li>반복적으로 학습, 예측 수행</li></ol><p>cross_val_score(estimator, X, y=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pred_dispatch=’2*n_jobs’)</p><ul><li>estimator : Classifier 또는 Regression</li><li>X : 피처 데이터세트</li><li>y : 레이블 데이터세트</li><li>scoring : 예측 성능 평가 지표</li><li>cv : 교차 검증 폴드 수</li></ul><p>반환값은 scoring 파라미터로 지정된 성능 지표 측정값을 배열 형태로 반환</p><p>cross_validate()는 여러 평가 지표를 반환할 수 있음</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> cross_val_score, cross_validate</span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">iris_data = load_iris()</span><br><span class="line">dt_clf = DecisionTreeClassifier(random_state=<span class="number">156</span>)</span><br><span class="line"></span><br><span class="line">data = iris_data.data</span><br><span class="line">label = iris_data.target</span><br><span class="line"></span><br><span class="line">scores = cross_val_score(dt_clf, data, label, scoring=<span class="string">&#x27;accuracy&#x27;</span>, cv=<span class="number">3</span>)</span><br><span class="line">print(<span class="string">&quot;교차 검증 정확도:&quot;</span>, np.<span class="built_in">round</span>(scores, <span class="number">4</span>))</span><br><span class="line">print(<span class="string">&quot;평균 검증 정확도:&quot;</span>, np.<span class="built_in">round</span>(np.mean(scores), <span class="number">4</span>))</span><br></pre></td></tr></table></figure><h3 id="GridSearchCV"><a href="#GridSearchCV" class="headerlink" title="GridSearchCV"></a>GridSearchCV</h3><hr><p>교차 검증, 최적 하이퍼 파라미터 튜닝<br>하이퍼 파라미터 : 머신러닝 알고리즘을 구성하는 주요 구성 요소<br>이 값을 조정해 알고리즘의 예측 성능 개선 가능</p><p>교차 검증 기반으로 하이퍼 파라미터의 최적 값을 찾게 해줌</p><p>파라미터</p><ul><li>estimator</li><li>param_grid : key + 리스트 값을 갖는 딕셔너리. estimator 튜닝을 위한 파라미터 명, 파라미터 값 지정</li><li>scoring : 예측 성능 평가 지표</li><li>cv : 교차 검증 폴드 수</li><li>refit : 가장 최적의 하이퍼파라미터 찾은 뒤 estimator 객체를 해당 하이퍼파라미터로 재학습시킴 (default = True)</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> GridSearchCV, train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=<span class="number">0.2</span>, random_state=<span class="number">121</span>)</span><br><span class="line"></span><br><span class="line">dtree = DecisionTreeClassifier(random_state=<span class="number">121</span>)</span><br><span class="line"></span><br><span class="line">parameters = &#123;<span class="string">&#x27;max_depth&#x27;</span>:[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="string">&#x27;min_samples_split&#x27;</span>:[<span class="number">2</span>, <span class="number">3</span>]&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">grid_dtree = GridSearchCV(dtree, param_grid=parameters, cv=<span class="number">3</span>, refit=<span class="literal">True</span>)</span><br><span class="line">grid_dtree.fit(X_train, y_train)</span><br><span class="line"></span><br><span class="line">scores_df = pd.DataFrame(grid_dtree.cv_results_)</span><br><span class="line">print(scores_df[[<span class="string">&#x27;params&#x27;</span>, <span class="string">&#x27;mean_test_score&#x27;</span>, <span class="string">&#x27;rank_test_score&#x27;</span>, <span class="string">&#x27;split0_test_score&#x27;</span>, <span class="string">&#x27;split1_test_score&#x27;</span>, <span class="string">&#x27;split2_test_score&#x27;</span>]])</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;GridSearchCV 최적 파라미터:&#x27;</span>, grid_dtree.best_params_)</span><br><span class="line">print(<span class="string">&#x27;GridSearchCV 최고 정확도:&#123;0:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(grid_dtree.best_score_))</span><br><span class="line"></span><br><span class="line">estimator = grid_dtree.best_estimator_</span><br><span class="line"></span><br><span class="line">pred = estimator.predict(X_test)</span><br><span class="line">print(<span class="string">&#x27;테스트 데이터 세트 정확도: &#123;0:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(accuracy_score(y_test, pred)))</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Machine-Learning/">Machine Learning</category>
      
      
      <category domain="https://github.aivillain.com/tags/%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D/">머신 러닝</category>
      
      <category domain="https://github.aivillain.com/tags/%EC%82%AC%EC%9D%B4%ED%82%B7-%EB%9F%B0/">사이킷 런</category>
      
      
      <comments>https://github.aivillain.com/2021/02/02/kr/Scikit-Learn-3/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Scikit-Learn-4 (데이터 전처리)</title>
      <link>https://github.aivillain.com/2021/02/02/kr/Scikit-Learn-4/</link>
      <guid>https://github.aivillain.com/2021/02/02/kr/Scikit-Learn-4/</guid>
      <pubDate>Mon, 01 Feb 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;This article is also</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>This article is also available in<a href="/2021/02/02/en/Scikit-Learn-4/">English</a>.</div></article><h3 id="데이터-전처리-Data-Preprocessing"><a href="#데이터-전처리-Data-Preprocessing" class="headerlink" title="데이터 전처리 (Data Preprocessing)"></a>데이터 전처리 (Data Preprocessing)</h3><hr><p>ML 알고리즘 적용 전 데이터에 대해 미리 처리해야 할 기본 사항</p><ul><li>Nan, Null값<br>고정된 다른 값으로 변환해야 함<br>얼마 되지 않는다면 피처의 평균값 등으로 대체할 수 있음<br>Null값이 대부분이라면 피처를 드롭하는 것이 더 좋음</li><li>문자열<br>입력 값으로 허용하지 않음<br>인코딩을 통해 숫자 형으로 변환해야 함<br>카테고리형, 텍스트형 피처로 구분<br>텍스트형 피처는 피처 벡터화 등의 기법으로 벡터화, 불필요하다면 드롭</li></ul><h3 id="데이터-인코딩"><a href="#데이터-인코딩" class="headerlink" title="데이터 인코딩"></a>데이터 인코딩</h3><hr><ul><li><p>레이블 인코딩<br>카테고리 피처를 코드형 숫자 값으로 변환</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelEncoder</span><br><span class="line"></span><br><span class="line">items=[<span class="string">&#x27;TV&#x27;</span>, <span class="string">&#x27;냉장고&#x27;</span>, <span class="string">&#x27;전자레인지&#x27;</span>, <span class="string">&#x27;컴퓨터&#x27;</span>, <span class="string">&#x27;선풍기&#x27;</span>, <span class="string">&#x27;선풍기&#x27;</span>, <span class="string">&#x27;믹서&#x27;</span>, <span class="string">&#x27;믹서&#x27;</span>]</span><br><span class="line"></span><br><span class="line">encoder = LabelEncoder()</span><br><span class="line">encoder.fit(items)</span><br><span class="line">labels = encoder.transform(items)</span><br><span class="line">print(<span class="string">&#x27;인코딩 변환값:&#x27;</span>, labels)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;인코딩 클래스:&#x27;</span>, encoder.classes_)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;디코딩 원본 값:&#x27;</span>, encoder.inverse_transform([<span class="number">4</span>, <span class="number">5</span>, <span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">3</span>, <span class="number">3</span>]))</span><br></pre></td></tr></table></figure></li><li><p>원-핫 인코딩<br>피처 값의 유형에 따라 새로운 피처를 추가<br>고유 값에 해당하는 컬럼에만 1 표시, 나머지 컬럼에는 0 표시</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> OneHotEncoder, LabelEncoder</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">items=[<span class="string">&#x27;TV&#x27;</span>, <span class="string">&#x27;냉장고&#x27;</span>, <span class="string">&#x27;전자레인지&#x27;</span>, <span class="string">&#x27;컴퓨터&#x27;</span>, <span class="string">&#x27;선풍기&#x27;</span>, <span class="string">&#x27;선풍기&#x27;</span>, <span class="string">&#x27;믹서&#x27;</span>, <span class="string">&#x27;믹서&#x27;</span>]</span><br><span class="line"></span><br><span class="line">encoder = LabelEncoder()</span><br><span class="line">encoder.fit(items)</span><br><span class="line">labels = encoder.transform(items)</span><br><span class="line"></span><br><span class="line">labels = labels.reshape(-<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">print(labels)</span><br><span class="line"></span><br><span class="line">oh_encoder = OneHotEncoder()</span><br><span class="line">oh_encoder.fit(labels)</span><br><span class="line">oh_labels = oh_encoder.transform(labels)</span><br><span class="line">print(<span class="string">&#x27;원-핫 인코딩 데이터&#x27;</span>)</span><br><span class="line">print(oh_labels.toarray())</span><br><span class="line">print(<span class="string">&quot;원-핫 인코더 데이터 차원&quot;</span>)</span><br><span class="line">print(oh_labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Pandas OneHotEncoding API</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">df = pd.DataFrame(&#123;<span class="string">&#x27;item&#x27;</span>:items&#125;)</span><br><span class="line">print(pd.get_dummies(df))</span><br></pre></td></tr></table></figure><h3 id="피처-스케일링과-정규화"><a href="#피처-스케일링과-정규화" class="headerlink" title="피처 스케일링과 정규화"></a>피처 스케일링과 정규화</h3></li></ul><hr><p>서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업<br>표준화, 정규화</p><ul><li><p>표준화(Standardization)<br>평균 0, 분산 1인 가우시안 정규 분포를 갖는 값으로 변환</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">iris_data = iris.data</span><br><span class="line">iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;feature들의 평균&#x27;</span>)</span><br><span class="line">print(iris_df.mean())</span><br><span class="line">print(<span class="string">&#x27;\nfeature들의 분산&#x27;</span>)</span><br><span class="line">print(iris_df.var())</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> StandardScaler <span class="comment"># 평균 0, 분산 1에 가깝게</span></span><br><span class="line"></span><br><span class="line">scaler = StandardScaler()</span><br><span class="line">scaler.fit(iris_df)</span><br><span class="line">iris_scaled = scaler.transform(iris_df)</span><br><span class="line"></span><br><span class="line">iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)</span><br><span class="line">print(<span class="string">&#x27;feature들의 평균&#x27;</span>)</span><br><span class="line">print(iris_df_scaled.mean())</span><br><span class="line">print(<span class="string">&#x27;\nfeature들의 분산&#x27;</span>)</span><br><span class="line">print(iris_df_scaled.var())</span><br></pre></td></tr></table></figure></li><li><p>정규화(Normalization)<br>서로 다른 피처 크기를 통일시키기 위해 크기를 변환<br>ex) MinMaxScaler</p>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">iris = load_iris()</span><br><span class="line">iris_data = iris.data</span><br><span class="line">iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> MinMaxScaler</span><br><span class="line"></span><br><span class="line">scaler = MinMaxScaler()</span><br><span class="line">scaler.fit(iris_df)</span><br><span class="line">iris_scaled = scaler.transform(iris_df)</span><br><span class="line"></span><br><span class="line">iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)</span><br><span class="line">print(<span class="string">&#x27;feature들의 최솟값&#x27;</span>)</span><br><span class="line">print(iris_df_scaled.<span class="built_in">min</span>())</span><br><span class="line">print(<span class="string">&#x27;\nfeature들의 최대값&#x27;</span>)</span><br><span class="line">print(iris_df_scaled.<span class="built_in">max</span>())</span><br></pre></td></tr></table></figure></li></ul>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Machine-Learning/">Machine Learning</category>
      
      
      <category domain="https://github.aivillain.com/tags/%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D/">머신 러닝</category>
      
      <category domain="https://github.aivillain.com/tags/%EC%82%AC%EC%9D%B4%ED%82%B7-%EB%9F%B0/">사이킷 런</category>
      
      
      <comments>https://github.aivillain.com/2021/02/02/kr/Scikit-Learn-4/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Machine Learning</title>
      <link>https://github.aivillain.com/2021/01/27/en/Machine-Learning/</link>
      <guid>https://github.aivillain.com/2021/01/27/en/Machine-Learning/</guid>
      <pubDate>Tue, 26 Jan 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;이 글은
&lt;a href=&quot;/2021/</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>이 글은<a href="/2021/01/27/kr/Machine-Learning/">한국어</a>로도 볼 수 있습니다.</div></article><article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-info-circle mr-2"></i>My English is not good. So if there is a grammatical error, please leave a comment.</div></article><h3 id="Machine-Learning"><a href="#Machine-Learning" class="headerlink" title="Machine Learning"></a>Machine Learning</h3><hr><p>Algorithm techniques for learning patterns based on data and predicting results<br>When developers create programs that take into account the nature of their data and work logic, <strong>useful for areas where difficulty and complexity of development are inevitably too high</strong></p><h3 id="The-field-of-machine-learning"><a href="#The-field-of-machine-learning" class="headerlink" title="The field of machine learning"></a>The field of machine learning</h3><hr><ul><li>Supervised Learning<ul><li>Classification</li><li>Regression</li><li>Recommanded System</li><li>Visual, Voice Recognition</li><li>Text analysis, NLP, etc.</li></ul></li><li>Unsupervised Learning<ul><li>Clustering</li><li>Dimensionality Reduction</li><li>Reinforcement learning, etc.</li></ul></li></ul><h3 id="The-biggest-drawback-of-machine-learning"><a href="#The-biggest-drawback-of-machine-learning" class="headerlink" title="The biggest drawback of machine learning"></a>The biggest drawback of machine learning</h3><hr><p><strong>Data-dependent</strong><br>Machine learning results can’t be good without good quality data<br>The ability to build optimal machine learning algorithms and model parameters is important, but the ability to <strong>process, process, and extract data efficiently</strong> is also important.</p>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Machine-Learning/">Machine Learning</category>
      
      
      <category domain="https://github.aivillain.com/tags/Machine-Learning/">Machine Learning</category>
      
      
      <comments>https://github.aivillain.com/2021/01/27/en/Machine-Learning/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Scikit-Learn-1 (Classification Example)</title>
      <link>https://github.aivillain.com/2021/01/27/en/Scikit-Learn-1/</link>
      <guid>https://github.aivillain.com/2021/01/27/en/Scikit-Learn-1/</guid>
      <pubDate>Tue, 26 Jan 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;이 글은
&lt;a href=&quot;/2021/</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>이 글은<a href="/2021/01/27/kr/Scikit-Learn-1/">한국어</a>로도 볼 수 있습니다.</div></article><article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-info-circle mr-2"></i>My English is not good. So if there is a grammatical error, please leave a comment.</div></article><h3 id="scikit-learn"><a href="#scikit-learn" class="headerlink" title="scikit-learn"></a>scikit-learn</h3><hr><p>The most popular Python machine learning library</p><h2 id="Classifying-varieties-with-brush-flower-data-set"><a href="#Classifying-varieties-with-brush-flower-data-set" class="headerlink" title="Classifying varieties with brush flower data set"></a>Classifying varieties with brush flower data set</h2><p>Prediction of flower varieties based on petal length, width, flower support length, and width</p><h3 id="Classification"><a href="#Classification" class="headerlink" title="Classification"></a>Classification</h3><hr><p>One of the most representative supervised learning methods</p><p>Practice Decision Tree algorithms</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">iris = load_iris() <span class="comment"># Load iris dataset</span></span><br><span class="line"></span><br><span class="line">iris_data = iris.data <span class="comment"># numpy data consisting of only input features</span></span><br><span class="line"></span><br><span class="line">iris_label = iris.target <span class="comment"># Prediction label</span></span><br><span class="line">print(<span class="string">&#x27;iris target값:&#x27;</span>, iris_label)</span><br><span class="line">print(<span class="string">&#x27;iris target명:&#x27;</span>, iris.target_names)</span><br><span class="line"></span><br><span class="line">iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names) <span class="comment"># make dataframe</span></span><br><span class="line">iris_df[<span class="string">&#x27;label&#x27;</span>] = iris.target</span><br><span class="line">print(iris_df.head(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Learn data, test data separation, feature x, label y,</span></span><br><span class="line"><span class="comment"># 80% learning data, 20% testing data</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris_data, iris_label,</span><br><span class="line">test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Creating a DecisionTreeClassifier object</span></span><br><span class="line">dt_clf = DecisionTreeClassifier(random_state=<span class="number">1</span>)</span><br><span class="line">dt_clf.fit(x_train, y_train) <span class="comment"># Model Learning</span></span><br><span class="line"></span><br><span class="line">pred = dt_clf.predict(x_test) <span class="comment"># Model Prediction</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score <span class="comment"># Get Accuracy</span></span><br><span class="line">print(<span class="string">&#x27;예측 정확도: &#123;0:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(accuracy_score(y_test, pred)))</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">1. Separation of data sets (learning data, test data separation)</span></span><br><span class="line"><span class="string">2. Model Learning</span></span><br><span class="line"><span class="string">3. Perform predictions</span></span><br><span class="line"><span class="string">4. Evaluation</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Machine-Learning/">Machine Learning</category>
      
      
      <category domain="https://github.aivillain.com/tags/Machine-Learning/">Machine Learning</category>
      
      <category domain="https://github.aivillain.com/tags/Scikit-learn/">Scikit learn</category>
      
      <category domain="https://github.aivillain.com/tags/Classification/">Classification</category>
      
      
      <comments>https://github.aivillain.com/2021/01/27/en/Scikit-Learn-1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Scikit-Learn-2</title>
      <link>https://github.aivillain.com/2021/01/27/en/Scikit-Learn-2/</link>
      <guid>https://github.aivillain.com/2021/01/27/en/Scikit-Learn-2/</guid>
      <pubDate>Tue, 26 Jan 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;이 글은
&lt;a href=&quot;/2021/</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>이 글은<a href="/2021/01/27/kr/Scikit-Learn-2/">한국어</a>로도 볼 수 있습니다.</div></article><article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-info-circle mr-2"></i>My English is not good. So if there is a grammatical error, please leave a comment.</div></article><h3 id="Understanding-the-Estimator"><a href="#Understanding-the-Estimator" class="headerlink" title="Understanding the Estimator"></a>Understanding the Estimator</h3><hr><p>In scikit-learn, classification algorithms are referred to as Classifier and regressor for regression algorithms.<br>The combination of Classifier and Regressor is called the Estimator class.<br>Model learning provides fit() and predictions using learned models provide predict() methods.</p><p>For classes that support evaluation functions such as cross_val_score(), and hyperparameter tuning such as GridSearchCV, the estimator is taken as a factor</p><p>Most classes that implement dimensionality reduction, clustering, feature extraction, etc. that are unsupervised learners also apply fit(), transform().<br>In unsupervised learning and feature extraction, fit() corresponds to a pre-structural task to transform data to fit the shape of the input data.<br>When structured with fit(), real-world operations such as dimension conversion, clustering, feature extraction, etc. of subsequent input data are performed with transform()<br>It also comes with fit_transform() that combines the two features.</p><p><a href="https://www.notion.so/69108a570a6e4314a8213c9fba1eef29">scikit-learn main package</a></p><h3 id="sklearn-datasets"><a href="#sklearn-datasets" class="headerlink" title="sklearn.datasets"></a>sklearn.datasets</h3><hr><ul><li>datasets.make_classificiation<br>Creating a dataset for classification<br>Randomly generate data for noise effects such as high correlation and unnecessary properties</li><li>datasets.make_bolbs()<br>Randomize dataset creation for clustering<br>Generate datasets for different clustering based on cluster-specified number</li></ul><p>The psychedelic dataset is in the form of a dictionary.</p><ul><li>data : Feature Dataset</li><li>target : Label value at classification, numeric result value at regression</li><li>target_names : Individual Label Name</li><li>feature_names : Feature Name</li><li>DESCR : Description of the dataset and each feature</li></ul><p>data, target is numpy array<br>target_names, feature_names is numpy array, or list type.<br>DESCR is a string type</p>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Machine-Learning/">Machine Learning</category>
      
      
      <category domain="https://github.aivillain.com/tags/Machine-Learning/">Machine Learning</category>
      
      <category domain="https://github.aivillain.com/tags/Scikit-learn/">Scikit learn</category>
      
      
      <comments>https://github.aivillain.com/2021/01/27/en/Scikit-Learn-2/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>머신 러닝 (Machine Learning)</title>
      <link>https://github.aivillain.com/2021/01/27/kr/Machine-Learning/</link>
      <guid>https://github.aivillain.com/2021/01/27/kr/Machine-Learning/</guid>
      <pubDate>Tue, 26 Jan 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;This article is also</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>This article is also available in<a href="/2021/01/27/en/Machine-Learning/">English</a>.</div></article><h3 id="머신러닝"><a href="#머신러닝" class="headerlink" title="머신러닝"></a>머신러닝</h3><hr><p>데이터를 기반으로 패턴을 학습, 결과를 예측하는 알고리즘 기법<br>개발자가 데이터, 업무 로직의 특성을 직접 감안한 프로그램을 만들 경우 <strong>난이도, 개발복잡도가 너무 높아질 수밖에 없는 분야</strong>에 유용</p><h3 id="머신러닝의-분류"><a href="#머신러닝의-분류" class="headerlink" title="머신러닝의 분류"></a>머신러닝의 분류</h3><hr><ul><li>지도학습<ul><li>분류</li><li>회귀</li><li>추천 시스템</li><li>시각, 음성 인지</li><li>텍스트 분석, NLP 등</li></ul></li><li>비지도학습<ul><li>클러스터링</li><li>차원 축소</li><li>강화 학습 등</li></ul></li></ul><h3 id="머신러닝의-최대-단점"><a href="#머신러닝의-최대-단점" class="headerlink" title="머신러닝의 최대 단점"></a>머신러닝의 최대 단점</h3><hr><p><strong>데이터 의존적</strong><br>좋은 품질의 데이터를 갖추지 못하면 머신러닝 수행 결과도 좋을 수 없음<br>최적의 머신러닝 알고리즘, 모델 파라미터를 구축하는 능력도 중요하지만 <strong>데이터를 효율적으로 가공, 처리, 추출</strong>하는 능력 또한 중요</p>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Machine-Learning/">Machine Learning</category>
      
      
      <category domain="https://github.aivillain.com/tags/%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D/">머신 러닝</category>
      
      
      <comments>https://github.aivillain.com/2021/01/27/kr/Machine-Learning/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Understanding CNN</title>
      <link>https://github.aivillain.com/2021/01/27/en/Understanding-CNN/</link>
      <guid>https://github.aivillain.com/2021/01/27/en/Understanding-CNN/</guid>
      <pubDate>Tue, 26 Jan 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;이 글은
&lt;a href=&quot;/2021/</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>이 글은<a href="/2021/01/27/kr/Understanding-CNN/">한국어</a>로도 볼 수 있습니다.</div></article><article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-info-circle mr-2"></i>My English is not good. So if there is a grammatical error, please leave a comment.</div></article><h3 id="CNN"><a href="#CNN" class="headerlink" title="CNN?"></a>CNN?</h3><hr><p>Cnovolutional Neural Network<br>Extracting the features of the input image through the convolutional layer and<br>performing classification based on them</p><h3 id="Convolutional-Layer"><a href="#Convolutional-Layer" class="headerlink" title="Convolutional Layer"></a>Convolutional Layer</h3><hr><p>Filter (Kernel) to extract features, configured as an Activation Function<br>to replace the value of the filter with a nonlinear value</p><p><img src="https://t1.daumcdn.net/cfile/tistory/23561441583ED6AB29" alt="https://t1.daumcdn.net/cfile/tistory/23561441583ED6AB29"></p><p>Filter doesn’t look at the whole thing, It looks at some parts.</p><p><img src="https://seungheondoh.netlify.app/static/f9d2d6bc7088c976eccd723d79bf7a14/2d017/10.CNN3.jpg" alt="https://seungheondoh.netlify.app/static/f9d2d6bc7088c976eccd723d79bf7a14/2d017/10.CNN3.jpg"></p>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Pytorch/">Pytorch</category>
      
      
      <category domain="https://github.aivillain.com/tags/Deep-learning/">Deep learning</category>
      
      <category domain="https://github.aivillain.com/tags/Convolutional-Neural-Network/">Convolutional Neural Network</category>
      
      
      <comments>https://github.aivillain.com/2021/01/27/en/Understanding-CNN/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Scikit-Learn-1 (분류 에제)</title>
      <link>https://github.aivillain.com/2021/01/27/kr/Scikit-Learn-1/</link>
      <guid>https://github.aivillain.com/2021/01/27/kr/Scikit-Learn-1/</guid>
      <pubDate>Tue, 26 Jan 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;This article is also</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>This article is also available in<a href="/2021/01/27/en/Scikit-Learn-1/">English</a>.</div></article><h3 id="scikit-learn"><a href="#scikit-learn" class="headerlink" title="scikit-learn"></a>scikit-learn</h3><hr><p>파이썬 머신러닝 라이브러리 중 가장 많이 사용되는 라이브러리</p><h2 id="붓꽃-데이터-세트로-붓꽃의-품종-분류하기"><a href="#붓꽃-데이터-세트로-붓꽃의-품종-분류하기" class="headerlink" title="붓꽃 데이터 세트로 붓꽃의 품종 분류하기"></a>붓꽃 데이터 세트로 붓꽃의 품종 분류하기</h2><p>꽃잎 길이, 너비, 꽃받침 길이, 너비를 기반으로 꽃의 품종 예측</p><h3 id="분류-Classification"><a href="#분류-Classification" class="headerlink" title="분류(Classification)"></a>분류(Classification)</h3><hr><p>대표적인 지도학습 방법의 하나</p><p>의사 결정 트리(Decision Tree) 알고리즘 실습</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">iris = load_iris() <span class="comment"># 붓꽃 데이터 세트 로드</span></span><br><span class="line"></span><br><span class="line">iris_data = iris.data <span class="comment"># 입력 피처만으로 된 numpy 데이터</span></span><br><span class="line"></span><br><span class="line">iris_label = iris.target <span class="comment"># 예측 label</span></span><br><span class="line">print(<span class="string">&#x27;iris target값:&#x27;</span>, iris_label)</span><br><span class="line">print(<span class="string">&#x27;iris target명:&#x27;</span>, iris.target_names)</span><br><span class="line"></span><br><span class="line">iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names) <span class="comment"># dataframe 생성</span></span><br><span class="line">iris_df[<span class="string">&#x27;label&#x27;</span>] = iris.target</span><br><span class="line">print(iris_df.head(<span class="number">3</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 학습 데이터, 테스트 데이터 분리, feature들을 x, label을 y로,</span></span><br><span class="line"><span class="comment"># 80% 학습 데이터, 20% 테스트 데이터</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris_data, iris_label,</span><br><span class="line">test_size=<span class="number">0.2</span>, random_state=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">dt_clf = DecisionTreeClassifier(random_state=<span class="number">1</span>) <span class="comment"># DecisionTreeClassifier 객체 생성</span></span><br><span class="line">dt_clf.fit(x_train, y_train) <span class="comment"># 모델 학습</span></span><br><span class="line"></span><br><span class="line">pred = dt_clf.predict(x_test) <span class="comment"># 모델 예측</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score <span class="comment"># 정확도 파악</span></span><br><span class="line">print(<span class="string">&#x27;예측 정확도: &#123;0:.4f&#125;&#x27;</span>.<span class="built_in">format</span>(accuracy_score(y_test, pred)))</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">1. 데이터 세트 분리 (학습 데이터, 테스트 데이터 분리)</span></span><br><span class="line"><span class="string">2. 모델 학습</span></span><br><span class="line"><span class="string">3. 예측 수행</span></span><br><span class="line"><span class="string">4. 평가</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Machine-Learning/">Machine Learning</category>
      
      
      <category domain="https://github.aivillain.com/tags/%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D/">머신 러닝</category>
      
      <category domain="https://github.aivillain.com/tags/%EC%82%AC%EC%9D%B4%ED%82%B7-%EB%9F%B0/">사이킷 런</category>
      
      <category domain="https://github.aivillain.com/tags/%EB%B6%84%EB%A5%98/">분류</category>
      
      
      <comments>https://github.aivillain.com/2021/01/27/kr/Scikit-Learn-1/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Scikit-Learn-2</title>
      <link>https://github.aivillain.com/2021/01/27/kr/Scikit-Learn-2/</link>
      <guid>https://github.aivillain.com/2021/01/27/kr/Scikit-Learn-2/</guid>
      <pubDate>Tue, 26 Jan 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;This article is also</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>This article is also available in<a href="/2021/01/27/en/Scikit-Learn-2/">English</a>.</div></article><h3 id="Estimator-이해"><a href="#Estimator-이해" class="headerlink" title="Estimator 이해"></a>Estimator 이해</h3><hr><p>scikit-learn에서 분류 알고리즘을 Classifier로, 회귀 알고리즘을 Regressor로 지칭<br>Classifier와 Regressor를 합쳐서 Estimator 클래스라고 부름<br>모델 학습은 fit(), 학습된 모델을 사용한 예측은 predict() 메소드 제공</p><p>cross_val_score()와 같은 evaluation 함수, GridSearchCV와 같은 하이퍼파라미터 튜닝을 지원하는 클래스의 경우 Estimator를 인자로 받음</p><p>비지도학습인 차원 축소, 클러스터링, 피처 추출 등을 구현한 클래스 역시 대부분 fit(), transform() 적용<br>비지도학습과 피처 추출에서 fit()은 입력 데이터의 형태에 맞춰 데이터를 변환하기 위한 사전 구조 작업에 해당<br>fit()으로 구조를 맞추면 이후 입력 데이터의 차원 변환, 클러스터링, 피처 추출 등 실제 작업은 transform()으로 수행<br>두 기능을 결합한 fit_transform()도 함께 제공</p><p><a href="https://www.notion.so/69108a570a6e4314a8213c9fba1eef29">scikit-learn 주요 패키지</a></p><h3 id="sklearn-datasets"><a href="#sklearn-datasets" class="headerlink" title="sklearn.datasets"></a>sklearn.datasets</h3><hr><ul><li>datasets.make_classificiation<br>분류를 위한 데이터 세트 생성<br>높은 상관도, 불필요한 속성 등 노이즈 효과를 위한 데이터를 무작위로 생성</li><li>datasets.make_bolbs()<br>클러스터링을 위한 데이터 세트 무작위 생성<br>군집 지정 개수에 따라 여러가지 클러스터링을 위한 데이터세트 생성</li></ul><p>사이킷런 데이터세트는 딕셔너리 형태로 되어있음</p><ul><li>data : 피처의 데이터세트</li><li>target : 분류 시 레이블 값, 회귀 시 숫자 결과값</li><li>target_names : 개별 레이블 이름</li><li>feature_names : 피처 이름</li><li>DESCR : 데이터 세트에 대한 설명, 각 피처 설명</li></ul><p>data, target은 넘파이 배열, target_names, feature_names는 넘파이 배열 또는 list 타입<br>DESCR은 스트링 타입</p>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Machine-Learning/">Machine Learning</category>
      
      
      <category domain="https://github.aivillain.com/tags/%EB%A8%B8%EC%8B%A0-%EB%9F%AC%EB%8B%9D/">머신 러닝</category>
      
      <category domain="https://github.aivillain.com/tags/%EC%82%AC%EC%9D%B4%ED%82%B7-%EB%9F%B0/">사이킷 런</category>
      
      
      <comments>https://github.aivillain.com/2021/01/27/kr/Scikit-Learn-2/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>CNN에 대한 이해</title>
      <link>https://github.aivillain.com/2021/01/27/kr/Understanding-CNN/</link>
      <guid>https://github.aivillain.com/2021/01/27/kr/Understanding-CNN/</guid>
      <pubDate>Tue, 26 Jan 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;This article is also</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>This article is also available in<a href="/2021/01/27/en/Understanding-CNN/">English</a>.</div></article><h3 id="CNN"><a href="#CNN" class="headerlink" title="CNN?"></a>CNN?</h3><hr><p>Cnovolutional Neural Network<br>컨볼루셔널 계층을 통해 입력 이미지의 특징(Feature)를 추출, 이를 기반으로 분류를 수행</p><h3 id="Convolutional-Layer"><a href="#Convolutional-Layer" class="headerlink" title="Convolutional Layer"></a>Convolutional Layer</h3><hr><p>특징을 추출하는 Filter(Kernel), 필터의 값을 비선형 값으로 바꾸는 Activation Function으로 구성</p><p><img src="https://t1.daumcdn.net/cfile/tistory/23561441583ED6AB29" alt="https://t1.daumcdn.net/cfile/tistory/23561441583ED6AB29"></p><p>Filter는 전체를 보는 것이 아닌 일부분을 집중해서 본다</p><p><img src="https://seungheondoh.netlify.app/static/f9d2d6bc7088c976eccd723d79bf7a14/2d017/10.CNN3.jpg" alt="https://seungheondoh.netlify.app/static/f9d2d6bc7088c976eccd723d79bf7a14/2d017/10.CNN3.jpg"></p>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Pytorch/">Pytorch</category>
      
      
      <category domain="https://github.aivillain.com/tags/Convolutional-Neural-Network/">Convolutional Neural Network</category>
      
      <category domain="https://github.aivillain.com/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</category>
      
      
      <comments>https://github.aivillain.com/2021/01/27/kr/Understanding-CNN/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Pytorch Autograd Practice</title>
      <link>https://github.aivillain.com/2021/01/26/en/Pytorch-Autograd-Practice/</link>
      <guid>https://github.aivillain.com/2021/01/26/en/Pytorch-Autograd-Practice/</guid>
      <pubDate>Mon, 25 Jan 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;이 글은
&lt;a href=&quot;/2021/</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>이 글은<a href="/2021/01/25/kr/Pytorch-Autograd/">한국어</a>로도 볼 수 있습니다.</div></article><article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-info-circle mr-2"></i>My English is not good. So if there is a grammatical error, please leave a comment.</div></article><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>) <span class="comment"># Record operations</span></span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line">y = x + <span class="number">2</span> <span class="comment"># Performing operations</span></span><br><span class="line">print(y)</span><br><span class="line"></span><br><span class="line">print(y.grad_fn) <span class="comment"># This is the result of the operation, so it has grad_fn.</span></span><br><span class="line"></span><br><span class="line">z = y*y*<span class="number">3</span> <span class="comment"># z = (x+2)^2*3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"></span><br><span class="line">print(z, out)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">.requires_gard_(...) changes the requirements_grad value of the existing Tensor to</span></span><br><span class="line"><span class="string">inplace. If no input value is specified, default is False</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">a = torch.randn(<span class="number">2</span>, <span class="number">2</span>) <span class="comment"># default requires_gard = False</span></span><br><span class="line">a = ((a * <span class="number">3</span>) / (a - <span class="number">1</span>))</span><br><span class="line">print(a.requires_grad) <span class="comment"># False</span></span><br><span class="line">a.requires_grad_(<span class="literal">True</span>) <span class="comment"># Operate inplace because _ is attached to the behind</span></span><br><span class="line">print(a.requires_grad) <span class="comment"># True</span></span><br><span class="line">b = (a * a).<span class="built_in">sum</span>() <span class="comment"># Grad_fn because it is the result of an operation of True</span></span><br><span class="line">print(b.grad_fn)</span><br><span class="line">print(b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># backprop</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">1. backprop of scalar value</span></span><br><span class="line"><span class="string"> = When the value is added to the differential result.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">x = a matrix containing two lines, two rows, 1</span></span><br><span class="line"><span class="string">y = x+2 == a matrix containing two-line, two-row, 3</span></span><br><span class="line"><span class="string">z = y*y*3 == a matrix containing two-line, two-row, 27 (3*(x+2)^2)</span></span><br><span class="line"><span class="string">out = Mean of z</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">out.backward() <span class="comment"># == out.backward(torch.tensor(1.))</span></span><br><span class="line"></span><br><span class="line">print(out)</span><br><span class="line">print(x.grad)</span><br><span class="line"><span class="comment"># The differential for x in the final equation in which x was used.</span></span><br><span class="line"><span class="comment"># (out = 3*(x+2)^2/4 -&gt; 3*(x+2)/2)</span></span><br><span class="line"><span class="comment"># (x = 1) (x = 1 is set in out.backward())</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">2. backprop of vector value</span></span><br><span class="line"><span class="string"> = Jacobian Matrix</span></span><br><span class="line"><span class="string"> (a matrix of all partial differential values for each dimension,</span></span><br><span class="line"><span class="string"> given that there is a function from m to n.)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"> Typical differential: deals with only one-variable functions</span></span><br><span class="line"><span class="string"> Partial differential: In multivariate functions,</span></span><br><span class="line"><span class="string"> </span></span><br><span class="line"><span class="string"> only one variable is a variable and the other is a constant.</span></span><br><span class="line"><span class="string"> The vector&#x27;s backprop is any value multiplied by the partial differential matrix.</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y = x * <span class="number">2</span> <span class="comment"># 2x</span></span><br><span class="line"><span class="keyword">while</span> y.data.norm() &lt; <span class="number">1000</span>:</span><br><span class="line">    y = y * <span class="number">2</span> <span class="comment"># 2^n*x</span></span><br><span class="line"></span><br><span class="line">print(y)</span><br><span class="line"></span><br><span class="line">v = torch.tensor([<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">0.0001</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">y.backward(v) <span class="comment"># 2^n multiplied by 0.1, 1.0, 0.0001</span></span><br><span class="line"></span><br><span class="line">print(x.grad)</span><br><span class="line"></span><br><span class="line">print(x.requires_grad)</span><br><span class="line">print((x ** <span class="number">2</span>).requires_grad)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad(): <span class="comment"># Stop Recording Tensor Operations</span></span><br><span class="line">    print((x ** <span class="number">2</span>).requires_grad)</span><br><span class="line"></span><br><span class="line">print(x.requires_grad)</span><br><span class="line">y = x.detach() <span class="comment"># Create a new Tensor with the same content but false require_grad</span></span><br><span class="line">print(y.requires_grad)</span><br><span class="line">print(x.eq(y).<span class="built_in">all</span>())</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Pytorch/">Pytorch</category>
      
      
      <category domain="https://github.aivillain.com/tags/Pytorch/">Pytorch</category>
      
      <category domain="https://github.aivillain.com/tags/Deep-learning/">Deep learning</category>
      
      
      <comments>https://github.aivillain.com/2021/01/26/en/Pytorch-Autograd-Practice/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Pytorch Neural Network</title>
      <link>https://github.aivillain.com/2021/01/26/en/Pytorch-Neural-Network/</link>
      <guid>https://github.aivillain.com/2021/01/26/en/Pytorch-Neural-Network/</guid>
      <pubDate>Mon, 25 Jan 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;이 글은
&lt;a href=&quot;/2021/</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>이 글은<a href="/2021/01/26/kr/Pytorch-Neural-Network/">한국어</a>로도 볼 수 있습니다.</div></article><article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-info-circle mr-2"></i>My English is not good. So if there is a grammatical error, please leave a comment.</div></article><h3 id="Neural-Network"><a href="#Neural-Network" class="headerlink" title="Neural Network"></a>Neural Network</h3><hr><p>Can be created using the torch.nn package<br>nn uses autograd to define and differentiate models<br>nn.Module contains forward(input) method that returns layer and output</p><h3 id="Typical-Learning-Process-of-Neural-Networks"><a href="#Typical-Learning-Process-of-Neural-Networks" class="headerlink" title="Typical Learning Process of Neural Networks"></a>Typical Learning Process of Neural Networks</h3><hr><ul><li>Define a neural network with learnable parameters (or weights)</li><li>Repeat Dataset Input</li><li>Propagate inputs from neural networks</li><li>Calculating loss</li><li>Backprop the gradient to the neural network parameters.</li><li>Updating the weight of a neural networks<br>(New Weight = Existing Weight - Learning_rate * Gradient)</li></ul><h3 id="Define-Neural-Network"><a href="#Define-Neural-Network" class="headerlink" title="Define Neural Network"></a>Define Neural Network</h3><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        1 input image channel, 6 output channels, 3x3 square convolution matrix</span></span><br><span class="line"><span class="string">        Convolutional Kernel Definitions</span></span><br><span class="line"><span class="string">        troch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0,</span></span><br><span class="line"><span class="string">        dilation=1, groups=1, bias=True)</span></span><br><span class="line"><span class="string">        in_channels(int) : Number of channel about input image. if rgb == 3</span></span><br><span class="line"><span class="string">        out_channels(int) : Number of channels created by convolution</span></span><br><span class="line"><span class="string">        kernel_size(int or tuple) : convoling_kernel size. (filter)</span></span><br><span class="line"><span class="string">        stride(int or tuple) : Stride size of convolution</span></span><br><span class="line"><span class="string">        default is 1, stride is the step size of the kernel when traversing the image</span></span><br><span class="line"><span class="string">        padding(int or tuple) : zero padding size</span></span><br><span class="line"><span class="string">        Default is 0 so zero padding is not applied if not set by default</span></span><br><span class="line"><span class="string">        self.conv1 = nn.Conv2d(1, 6, 3)</span></span><br><span class="line"><span class="string">        self.conv2 = nn.Conv2d(6, 16, 3)</span></span><br><span class="line"><span class="string">        Affine operation : y=Wx+b</span></span><br><span class="line"><span class="string">        self.fc1 = nn.Linear(16*6*6, 120) # 6*6 is image dimension</span></span><br><span class="line"><span class="string">        self.fc2 = nn.Linear(120, 84)</span></span><br><span class="line"><span class="string">        self.fc3 = nn.Linear(84, 10)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># Max pooling for (2, 2) size windows</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># If the size is a square number, specify only one number</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, self.num_flat_features(x))</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        size = x.size()[<span class="number">1</span>:] <span class="comment"># All dimensions except batch dimensions</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure><p align="center">  <img src="https://cdn-images-1.medium.com/max/1200/1*1okwhewf5KCtIPaFib4XaA.gif"></p><p align="center"><em>2D convolution using a kernel size of 3, stride of 1 and padding</em></p><p>If you define a forward function only, the backward function is automatically defined using autograd.<br>You can use any Tensor operation in the forward function.<br>The model’s learnable parameters are returned by net.parameters()</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">params = <span class="built_in">list</span>(net.parameters())</span><br><span class="line">print(<span class="built_in">len</span>(params))</span><br><span class="line">print(params[<span class="number">0</span>].size())</span><br><span class="line"></span><br><span class="line"><span class="comment"># Enter any 32x32 value</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">out = net(<span class="built_in">input</span>)</span><br><span class="line">print(out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set all parameters to zero degrees of change buffer,</span></span><br><span class="line"><span class="comment"># backpropagating to random values</span></span><br><span class="line">net.zero_grad()</span><br><span class="line">out.backward(torch.rand(<span class="number">1</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss function</span></span><br><span class="line"><span class="comment"># Take output, target as a pair of inputs and calculate the estimate of</span></span><br><span class="line"><span class="comment"># how far the output is from the correct answer.</span></span><br><span class="line"><span class="comment"># nn.MSEloss calculates mean square error between output and target</span></span><br><span class="line"><span class="comment"># as a simple loss function</span></span><br><span class="line">output = net(<span class="built_in">input</span>)</span><br><span class="line">target = torch.randn(<span class="number">10</span>) <span class="comment"># Example for comparison, random correct answer</span></span><br><span class="line">target = target.view(<span class="number">1</span>, -<span class="number">1</span>) <span class="comment"># Convert to same shape as output</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">loss = criterion(output, target)</span><br><span class="line">print(loss)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d</span></span><br><span class="line"><span class="string">      -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear</span></span><br><span class="line"><span class="string">      -&gt; MSELoss</span></span><br><span class="line"><span class="string">      -&gt; loss</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># .grad Tensor with accumulated variability</span></span><br><span class="line">print(loss.grad_fn)</span><br><span class="line">print(loss.grad_fn.next_functions[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">print(loss.grad_fn.next_functions[<span class="number">0</span>][<span class="number">0</span>].next_functions[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># backprop</span></span><br><span class="line"><span class="comment"># If you don&#x27;t eliminate the traditional changes,</span></span><br><span class="line"><span class="comment"># they accumulate in the existing ones.</span></span><br><span class="line">net.zero_grad()</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;conv1.bias.grad before backward&#x27;</span>) <span class="comment"># Initialized to 0</span></span><br><span class="line">print(net.conv1.bias.grad)</span><br><span class="line"></span><br><span class="line">loss.backward() <span class="comment"># loss = criterion(output, target)</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;conv1.bias.grad after backward&#x27;</span>)</span><br><span class="line">print(net.conv1.bias.grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Updating Weight</span></span><br><span class="line"><span class="comment"># Stochastic gradient descent(SGD)</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> net.parameters():</span><br><span class="line">    f.data.sub_(f.grad.data * learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># implemented various renewal rules such as SGD, Nesterov-SGD, Adam,and RMSProp</span></span><br><span class="line"><span class="comment"># in a small package called torch.optim</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create Optimizer</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training process</span></span><br><span class="line"><span class="comment"># Manually set the change chart buffer to zero using optimizer.zero_grad()</span></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">output = net(<span class="built_in">input</span>)</span><br><span class="line">loss = criterion(output, target)</span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Pytorch/">Pytorch</category>
      
      
      <category domain="https://github.aivillain.com/tags/Pytorch/">Pytorch</category>
      
      <category domain="https://github.aivillain.com/tags/Deep-learning/">Deep learning</category>
      
      
      <comments>https://github.aivillain.com/2021/01/26/en/Pytorch-Neural-Network/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Pytorch Autograd 실습</title>
      <link>https://github.aivillain.com/2021/01/26/kr/Pytorch-Autograd-Practice/</link>
      <guid>https://github.aivillain.com/2021/01/26/kr/Pytorch-Autograd-Practice/</guid>
      <pubDate>Mon, 25 Jan 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;This article is also</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>This article is also available in<a href="/2021/01/26/en/Pytorch-Autograd-Practice/">English</a>.</div></article><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">x = torch.ones(<span class="number">2</span>, <span class="number">2</span>, requires_grad=<span class="literal">True</span>) <span class="comment"># 연산을 기록</span></span><br><span class="line">print(x)</span><br><span class="line"></span><br><span class="line">y = x + <span class="number">2</span> <span class="comment"># 연산 수행</span></span><br><span class="line">print(y)</span><br><span class="line"></span><br><span class="line">print(y.grad_fn) <span class="comment"># 연산 결과이므로 grad_fn을 가짐</span></span><br><span class="line"></span><br><span class="line">z = y*y*<span class="number">3</span> <span class="comment"># z = (x+2)^2*3</span></span><br><span class="line">out = z.mean()</span><br><span class="line"></span><br><span class="line">print(z, out)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">.requires_gard_(...)는 기존 Tensor의 requires_grad 값을 inplace 방식으로 변경.</span></span><br><span class="line"><span class="string">입력값 지정되지 않으면 default는 False</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">a = torch.randn(<span class="number">2</span>, <span class="number">2</span>) <span class="comment"># 기본 requires_gard = False</span></span><br><span class="line">a = ((a * <span class="number">3</span>) / (a - <span class="number">1</span>))</span><br><span class="line">print(a.requires_grad) <span class="comment"># False</span></span><br><span class="line">a.requires_grad_(<span class="literal">True</span>) <span class="comment"># _가 뒤에 붙어있기 때문에 inplace 연산</span></span><br><span class="line">print(a.requires_grad) <span class="comment"># True</span></span><br><span class="line">b = (a * a).<span class="built_in">sum</span>() <span class="comment"># True의 연산 결과이므로 grad_fn 가짐</span></span><br><span class="line">print(b.grad_fn)</span><br><span class="line">print(b)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 역전파(backprop)</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">1. scalar 값의 backprop</span></span><br><span class="line"><span class="string"> = 미분 결과에 해당 값을 넣었을 때.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">x = 2행 2열짜리 1이 들어있는 행렬</span></span><br><span class="line"><span class="string">y = x+2 == 2행 2열짜리 3이 들어있는 행렬</span></span><br><span class="line"><span class="string">z = y*y*3 == 2행 2열 27이 들어있는 행렬 (3*(x+2)^2)</span></span><br><span class="line"><span class="string">out = z의 평균</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">out.backward() <span class="comment"># == out.backward(torch.tensor(1.))</span></span><br><span class="line"></span><br><span class="line">print(out)</span><br><span class="line">print(x.grad)</span><br><span class="line"><span class="comment"># x가 사용된 최종 연산식에서 x에대한 미분(out = 3*(x+2)^2/4 -&gt; 3*(x+2)/2)</span></span><br><span class="line"><span class="comment"># (x = 1) (x = 1은 out.backward()에서 설정됨)</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">2. vector의 backprop</span></span><br><span class="line"><span class="string"> = Jacobian Matrix</span></span><br><span class="line"><span class="string"> (m차원에서 n차원으로 가는 함수가 있다고 할 때 각각 차원에 대해</span></span><br><span class="line"><span class="string"> 모든 편미분 값을 모아놓은 matrix)</span></span><br><span class="line"><span class="string"> 일반적인 미분 : 1변수 함수만 다룸</span></span><br><span class="line"><span class="string"> 편미분 : 다변수 함수에서 한 변수만 변수로, 나머지 변수는 상수로</span></span><br><span class="line"><span class="string"> vector의 backprop은 편미분값 matrix에 곱해주는 어떤 값</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">x = torch.rand(<span class="number">3</span>, requires_grad=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">y = x * <span class="number">2</span> <span class="comment"># 2x</span></span><br><span class="line"><span class="keyword">while</span> y.data.norm() &lt; <span class="number">1000</span>:</span><br><span class="line">    y = y * <span class="number">2</span> <span class="comment"># 2^n*x</span></span><br><span class="line"></span><br><span class="line">print(y)</span><br><span class="line"></span><br><span class="line">v = torch.tensor([<span class="number">0.1</span>, <span class="number">1.0</span>, <span class="number">0.0001</span>], dtype=torch.<span class="built_in">float</span>)</span><br><span class="line">y.backward(v) <span class="comment"># 2^n에 0.1, 1.0, 0.0001 곱해준 값</span></span><br><span class="line"></span><br><span class="line">print(x.grad)</span><br><span class="line"></span><br><span class="line">print(x.requires_grad)</span><br><span class="line">print((x ** <span class="number">2</span>).requires_grad)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> torch.no_grad(): <span class="comment"># Tensor 연산 기록 멈춤</span></span><br><span class="line">    print((x ** <span class="number">2</span>).requires_grad)</span><br><span class="line"></span><br><span class="line">print(x.requires_grad)</span><br><span class="line">y = x.detach() <span class="comment"># content는 같지만 require_grad가 False인 새로운 Tensor 생성</span></span><br><span class="line">print(y.requires_grad)</span><br><span class="line">print(x.eq(y).<span class="built_in">all</span>())</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Pytorch/">Pytorch</category>
      
      
      <category domain="https://github.aivillain.com/tags/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98/">파이토치</category>
      
      <category domain="https://github.aivillain.com/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</category>
      
      
      <comments>https://github.aivillain.com/2021/01/26/kr/Pytorch-Autograd-Practice/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Pytorch 신경망</title>
      <link>https://github.aivillain.com/2021/01/26/kr/Pytorch-Neural-Network/</link>
      <guid>https://github.aivillain.com/2021/01/26/kr/Pytorch-Neural-Network/</guid>
      <pubDate>Mon, 25 Jan 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;This article is also</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>This article is also available in<a href="/2021/01/26/en/Pytorch-Neural-Network/">English</a>.</div></article><h3 id="신경망"><a href="#신경망" class="headerlink" title="신경망"></a>신경망</h3><hr><p>torch.nn 패키지를 사용하여 생성 가능<br>nn은 모델을 정의하고 미분하는데 autograd 사용<br>nn.Module은 layer와 output을 반환하는 forward(input) 메서드 포함</p><h3 id="신경망의-일반적인-학습-과정"><a href="#신경망의-일반적인-학습-과정" class="headerlink" title="신경망의 일반적인 학습 과정"></a>신경망의 일반적인 학습 과정</h3><hr><ul><li>학습 가능한 매개변수(또는 가중치(weight))를 갖는 신경망 정의</li><li>데이터셋 입력 반복</li><li>입력을 신경망에서 전파</li><li>손실(loss) 계산</li><li>변화도(gradient)를 신경망 매개변수들에 역전파</li><li>신경망의 가중치 갱신<br>(새로운 가중치 = 기존 가중치 - 학습률(learning_rate) * 변화도(gradient)</li></ul><h3 id="신경망-정의"><a href="#신경망-정의" class="headerlink" title="신경망 정의"></a>신경망 정의</h3><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span>(<span class="params">nn.Module</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        입력 이미지 채널 1개, 출력 채널 6개, 3x3의 정사각 컨볼루션 행렬</span></span><br><span class="line"><span class="string">        컨볼루션 커널 정의</span></span><br><span class="line"><span class="string">        troch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0,</span></span><br><span class="line"><span class="string">        dilation=1, groups=1, bias=True)</span></span><br><span class="line"><span class="string">        in_channels(int) : input image의 channel수. rgb면 3</span></span><br><span class="line"><span class="string">        out_channels(int) : convolution에 의해 생성된 channel 수</span></span><br><span class="line"><span class="string">        kernel_size(int or tuple) : convoling_kernel 크기. (filter)</span></span><br><span class="line"><span class="string">        stride(int or tuple) : convolution의 stride를 얼만큼 줄 것인가.</span></span><br><span class="line"><span class="string">        default는 1, stride는 이미지 횡단 시 커널의 스텝 사이즈</span></span><br><span class="line"><span class="string">        padding(int or tuple) : zero padding을 input 양쪽 인자만큼.</span></span><br><span class="line"><span class="string">        default는 0이라서 기본적으로 설정하지 않을 경우 zero padding 적용하지 않음</span></span><br><span class="line"><span class="string">        self.conv1 = nn.Conv2d(1, 6, 3)</span></span><br><span class="line"><span class="string">        self.conv2 = nn.Conv2d(6, 16, 3)</span></span><br><span class="line"><span class="string">        아핀(affine) 연산: y = Wx + b</span></span><br><span class="line"><span class="string">        self.fc1 = nn.Linear(16*6*6, 120) # 6*6은 이미지 차원</span></span><br><span class="line"><span class="string">        self.fc2 = nn.Linear(120, 84)</span></span><br><span class="line"><span class="string">        self.fc3 = nn.Linear(84, 10)</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="comment"># (2, 2) 크기 윈도우에 대해 맥스 풀링(max pooling)</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv1(x)), (<span class="number">2</span>, <span class="number">2</span>))</span><br><span class="line">        <span class="comment"># 크기가 제곱수라면 하나의 숫자만을 특정</span></span><br><span class="line">        x = F.max_pool2d(F.relu(self.conv2(x)), <span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, self.num_flat_features(x))</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">num_flat_features</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        size = x.size()[<span class="number">1</span>:] <span class="comment"># 배치 차원을 제외한 모든 차원</span></span><br><span class="line">        num_features = <span class="number">1</span></span><br><span class="line">        <span class="keyword">for</span> s <span class="keyword">in</span> size:</span><br><span class="line">            num_features *= s</span><br><span class="line">        <span class="keyword">return</span> num_features</span><br><span class="line"></span><br><span class="line">net = Net()</span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure><p align="center">  <img src="https://cdn-images-1.medium.com/max/1200/1*1okwhewf5KCtIPaFib4XaA.gif"></p><p align="center"><em>2D convolution using a kernel size of 3, stride of 1 and padding</em></p><p>forward 함수만 정의하면, backward 함수는 autograd를 사용하여 자동으로 정의됨.<br>forward 함수에서는 어떠한 Tensor 연산을 사용해도 됨<br>모델의 학습 가능 매개변수는 net.parameters()에 의해 반환됨</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">params = <span class="built_in">list</span>(net.parameters())</span><br><span class="line">print(<span class="built_in">len</span>(params))</span><br><span class="line">print(params[<span class="number">0</span>].size())</span><br><span class="line"></span><br><span class="line"><span class="comment"># 임의의 32x32값 입력</span></span><br><span class="line"><span class="built_in">input</span> = torch.randn(<span class="number">1</span>, <span class="number">1</span>, <span class="number">32</span>, <span class="number">32</span>)</span><br><span class="line">out = net(<span class="built_in">input</span>)</span><br><span class="line">print(out)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 모든 매개변수의 변화도 버퍼를 0으로 설정, 무작위 값으로 역전파</span></span><br><span class="line">net.zero_grad()</span><br><span class="line">out.backward(torch.rand(<span class="number">1</span>, <span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 손실 함수</span></span><br><span class="line"><span class="comment"># output, target을 한 쌍의 입력으로 받아, 출력이 정답으로부터 얼마나 멀리 떨어져있는지</span></span><br><span class="line"><span class="comment"># 추정하는 값을 계산</span></span><br><span class="line"><span class="comment"># 간단한 손실 함수로 출력과 대상 간 평균제곱오차를 계산하는 nn.MSEloss가 있음</span></span><br><span class="line">output = net(<span class="built_in">input</span>)</span><br><span class="line">target = torch.randn(<span class="number">10</span>) <span class="comment"># 비교를 위한 예시, 임의의 정답</span></span><br><span class="line">target = target.view(<span class="number">1</span>, -<span class="number">1</span>) <span class="comment"># 출력과 같은 shape로 변환</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line"></span><br><span class="line">loss = criterion(output, target)</span><br><span class="line">print(loss)</span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">input -&gt; conv2d -&gt; relu -&gt; maxpool2d -&gt; conv2d -&gt; relu -&gt; maxpool2d</span></span><br><span class="line"><span class="string">      -&gt; view -&gt; linear -&gt; relu -&gt; linear -&gt; relu -&gt; linear</span></span><br><span class="line"><span class="string">      -&gt; MSELoss</span></span><br><span class="line"><span class="string">      -&gt; loss</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="comment"># 변화도가 누적된 .grad Tensor</span></span><br><span class="line">print(loss.grad_fn)</span><br><span class="line">print(loss.grad_fn.next_functions[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line">print(loss.grad_fn.next_functions[<span class="number">0</span>][<span class="number">0</span>].next_functions[<span class="number">0</span>][<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 역전파</span></span><br><span class="line"><span class="comment"># 기존 변화도를 없애지 않으면 기존의 변화도에 누적됨</span></span><br><span class="line">net.zero_grad()</span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;conv1.bias.grad before backward&#x27;</span>) <span class="comment"># 0으로 초기화되어있음</span></span><br><span class="line">print(net.conv1.bias.grad)</span><br><span class="line"></span><br><span class="line">loss.backward() <span class="comment"># loss = criterion(output, target)</span></span><br><span class="line"></span><br><span class="line">print(<span class="string">&#x27;conv1.bias.grad after backward&#x27;</span>)</span><br><span class="line">print(net.conv1.bias.grad)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 가중치 갱신</span></span><br><span class="line"><span class="comment"># 확률적 경사하강법</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"><span class="keyword">for</span> f <span class="keyword">in</span> net.parameters():</span><br><span class="line">    f.data.sub_(f.grad.data * learning_rate)</span><br><span class="line"></span><br><span class="line"><span class="comment"># torch.optim이라는 작은 패키지에 SGD, Nesterov-SGD, Adam, RMSProp등</span></span><br><span class="line"><span class="comment"># 다양한 갱신 규칙을 구현해두었음</span></span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># Optimizer 생성</span></span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 학습 과정</span></span><br><span class="line"><span class="comment"># optimizer.zero_grad()를 사용하여 수동으로 변화도 버퍼를 0으로 설정</span></span><br><span class="line">optimizer.zero_grad()</span><br><span class="line">output = net(<span class="built_in">input</span>)</span><br><span class="line">loss = criterion(output, target)</span><br><span class="line">loss.backward()</span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Pytorch/">Pytorch</category>
      
      
      <category domain="https://github.aivillain.com/tags/%ED%8C%8C%EC%9D%B4%ED%86%A0%EC%B9%98/">파이토치</category>
      
      <category domain="https://github.aivillain.com/tags/%EB%94%A5%EB%9F%AC%EB%8B%9D/">딥러닝</category>
      
      
      <comments>https://github.aivillain.com/2021/01/26/kr/Pytorch-Neural-Network/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Pytorch Autograd</title>
      <link>https://github.aivillain.com/2021/01/25/en/Pytorch-Autograd/</link>
      <guid>https://github.aivillain.com/2021/01/25/en/Pytorch-Autograd/</guid>
      <pubDate>Sun, 24 Jan 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;이 글은
&lt;a href=&quot;/2021/</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>이 글은<a href="/2021/01/25/kr/Pytorch-Autograd/">한국어</a>로도 볼 수 있습니다.</div></article><article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-info-circle mr-2"></i>My English is not good. So if there is a grammatical error, please leave a comment.</div></article><h3 id="Autogard"><a href="#Autogard" class="headerlink" title="Autogard"></a>Autogard</h3><hr><ul><li>autogard package provides automatic differentiation for all operations of the Tensor.<br>  Setting the <strong>.requires_gard property to True</strong> in the torch.Tensor class tracks all operations performed on that sensor.<br>  After the calculation is complete, you can call <strong>.backward()</strong> to <strong>automatically calculate the gradient</strong></li></ul><ul><li>To stop Tensor from tracking records, you can call <strong>.detach()</strong> to separate from the computational history<br>  Code blocks can be wrapped <strong>with torch.no_gard():</strong> to avoid historical tracking and memory usage<br>  Useful for evaluating models with learnable parameters, set to <strong>require_guard=True</strong>, although gradients are not required.</li></ul><ul><li>Function Class<br>  Tensor and Function are interconnected and encode all computational processes to create non-circulating graphs<br>  Each Tensor has a <strong>.gard_fn</strong> property, which refers to the Function that generated the Tensor<br>  <strong>(The gradient_fn of the user-generated Tensor is None)</strong><br>  The derivative calculation calls the .backward() of the Tensor<br>  Backward does not require factors if Tensor is Scally, but when it has <strong>multiple elements, it is necessary to shape the Tensor as a factor of gradient</strong>.</li></ul>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Pytorch/">Pytorch</category>
      
      
      <category domain="https://github.aivillain.com/tags/Pytorch/">Pytorch</category>
      
      <category domain="https://github.aivillain.com/tags/Deep-learning/">Deep learning</category>
      
      
      <comments>https://github.aivillain.com/2021/01/25/en/Pytorch-Autograd/#disqus_thread</comments>
      
    </item>
    
    <item>
      <title>Create, Operate, Convert Pytorch Tensor</title>
      <link>https://github.aivillain.com/2021/01/25/en/Pytorch-Tensor/</link>
      <guid>https://github.aivillain.com/2021/01/25/en/Pytorch-Tensor/</guid>
      <pubDate>Sun, 24 Jan 2021 15:00:00 GMT</pubDate>
      
        
        
      <description>&lt;article class=&quot;message message-immersive is-primary&quot;&gt;
&lt;div class=&quot;message-body&quot;&gt;
&lt;i class=&quot;fas fa-globe-asia mr-2&quot;&gt;&lt;/i&gt;이 글은
&lt;a href=&quot;/2021/</description>
        
      
      
      
      <content:encoded><![CDATA[<article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-globe-asia mr-2"></i>이 글은<a href="/2021/01/25/kr/Pytorch-Tensor/">한국어</a>로도 볼 수 있습니다.</div></article><article class="message message-immersive is-primary"><div class="message-body"><i class="fas fa-info-circle mr-2"></i>My English is not good. So if there is a grammatical error, please leave a comment.</div></article><h3 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch?"></a>Pytorch?</h3><hr><p>Python Library Helps Build Deep Learning Projects<br>Provides a tensor, a core data structure (multi-dimensional array similar to the numpy array)<br>Tensor accelerates mathematical operations (GPU available)</p><p>It is mostly made of C++ and CUDA for performance reasons.</p><h3 id="Installation"><a href="#Installation" class="headerlink" title="Installation"></a>Installation</h3><hr><p><a href="https://pytorch.org/get-started/locally/">PyTorch Installation Link</a></p><p>Copy Run this Command after setting it to your environment.</p><h3 id="Check-GPU"><a href="#Check-GPU" class="headerlink" title="Check GPU"></a>Check GPU</h3><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"></span><br><span class="line">print(torch.cuda.get_device_name(<span class="number">0</span>))</span><br><span class="line">print(torch.cuda.is_available())</span><br></pre></td></tr></table></figure><h3 id="Create-Tensor"><a href="#Create-Tensor" class="headerlink" title="Create Tensor"></a>Create Tensor</h3><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The values that existed in the memory allocated at that time appear as</span></span><br><span class="line"><span class="comment"># initial values.</span></span><br><span class="line">x = torch.empty(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># Randomly initialized matrix (0 = x &lt; 1)</span></span><br><span class="line">x = torch.rand(<span class="number">5</span>, <span class="number">3</span>) </span><br><span class="line"><span class="comment"># dtype = long, Matrix filled with zeros</span></span><br><span class="line">x = torch.zeros(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.long) </span><br><span class="line"><span class="comment"># Create tensor with list</span></span><br><span class="line">x = torch.tensor([<span class="number">5.5</span>, <span class="number">3</span>]) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Create new Tensor based on existing Tensor</span></span><br><span class="line">x = x.new_ones(<span class="number">5</span>, <span class="number">3</span>, dtype=torch.double) </span><br><span class="line"><span class="comment"># Create new Tensor based on existing Tensor</span></span><br><span class="line">x = torch.randn_like(x, dtype=torch.<span class="built_in">float</span>) </span><br><span class="line"><span class="comment"># Obtain matrix size, return torch.Size supports tuple types, all tuple operations</span></span><br><span class="line">x.size() </span><br></pre></td></tr></table></figure><h3 id="Tensor-Operation"><a href="#Tensor-Operation" class="headerlink" title="Tensor Operation"></a>Tensor Operation</h3><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Operation 1</span></span><br><span class="line">y = torch.rand(<span class="number">5</span>, <span class="number">3</span>) </span><br><span class="line">print(x + y)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Operation 2</span></span><br><span class="line">print(torch.add(x, y)) </span><br><span class="line"></span><br><span class="line">result = torch.empty(<span class="number">5</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># Operation 3</span></span><br><span class="line">torch.add(x, y, out=result) </span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure><h3 id="Change-Tensor-shape-and-convert-to-numpy-array"><a href="#Change-Tensor-shape-and-convert-to-numpy-array" class="headerlink" title="Change Tensor shape and convert to numpy array"></a>Change Tensor shape and convert to numpy array</h3><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># When changing size and shape of sensor, use torch.view</span></span><br><span class="line">x = torch.rand(<span class="number">4</span>, <span class="number">4</span>)</span><br><span class="line">y = x.view(<span class="number">16</span>)</span><br><span class="line">z = x.view(-<span class="number">1</span>, <span class="number">8</span>)</span><br><span class="line">print(x.size(), y.size(), z.size())</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">1</span>)</span><br><span class="line">print(x)</span><br><span class="line"><span class="comment"># If only one value exists in the tensor, a numeric value can be obtained</span></span><br><span class="line"><span class="comment"># using .item()</span></span><br><span class="line">print(x.item()) </span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert torch tensor to numpy array</span></span><br><span class="line">a = torch.ones(<span class="number">5</span>)</span><br><span class="line">print(a)</span><br><span class="line">b = a.numpy()</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure><h3 id="CPU-GPU-Tensor-Change"><a href="#CPU-GPU-Tensor-Change" class="headerlink" title="CPU, GPU Tensor Change"></a>CPU, GPU Tensor Change</h3><hr><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Run only in CUDA-enabled environments (GPU environments)</span></span><br><span class="line"><span class="keyword">if</span> torch.cuda.is_available(): </span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span>)</span><br><span class="line">    <span class="comment"># Create a direct tensor on a GPU</span></span><br><span class="line">    y = torch.ones_like(x, device=device) </span><br><span class="line">    <span class="comment"># Change CPU Tensor to GPU Tensor</span></span><br><span class="line">    x = x.to(device) </span><br><span class="line">    z = x + y</span><br><span class="line">    print(z)</span><br><span class="line">    print(z.to(<span class="string">&quot;cpu&quot;</span>, torch.double))</span><br></pre></td></tr></table></figure>]]></content:encoded>
      
      
      <category domain="https://github.aivillain.com/categories/Pytorch/">Pytorch</category>
      
      
      <category domain="https://github.aivillain.com/tags/Pytorch/">Pytorch</category>
      
      <category domain="https://github.aivillain.com/tags/Deep-learning/">Deep learning</category>
      
      
      <comments>https://github.aivillain.com/2021/01/25/en/Pytorch-Tensor/#disqus_thread</comments>
      
    </item>
    
  </channel>
</rss>
